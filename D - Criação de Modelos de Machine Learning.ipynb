{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b43a122",
   "metadata": {},
   "source": [
    "# PONTIFÍCIA UNIVERSIDADE CATÓLICA DE MINAS GERAIS\n",
    "##  Pós-graduação Lato Sensu em Ciência de Dados e Big Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d0e519",
   "metadata": {},
   "source": [
    "## ANÁLISE TEMPORAL DA GESTÃO DE ESGOTOS EM GOIÁS (1992-2021) E PERSPECTIVAS FUTURAS (2022-2032)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c5907",
   "metadata": {},
   "source": [
    "### ADENILSON ALVES DA SILVA - 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef420ca",
   "metadata": {},
   "source": [
    "# D - Criação de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cce384",
   "metadata": {},
   "source": [
    "Versão Python: 3.11.4\n",
    "\n",
    "Realizar as seguintes instalações:\n",
    "- pip install pandas==1.3.4\n",
    "- pip install matplotlib==3.4.3\n",
    "- pip install statsmodels==0.12.2\n",
    "- pip install Numpy==1.23.5\n",
    "- pip install tabulate==0.9.0\n",
    "- pip install pyclustering==0.10.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50fa89",
   "metadata": {},
   "source": [
    "####  1 - Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1cbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Biblioteca para trabalhar com dados em formato de tabela (DataFrame)\n",
    "import matplotlib.pyplot as plt  # Biblioteca para criação de gráficos\n",
    "import numpy as np  # Biblioteca para manipulação de arrays numéricos\n",
    "import matplotlib.gridspec as gridspec  # Biblioteca para criação de layouts de gráficos personalizados\n",
    "import itertools  # Biblioteca para iteração eficiente\n",
    "import random  # Biblioteca para geração de números aleatórios\n",
    "import seaborn as sns  # Biblioteca para visualização de dados baseada no Matplotlib\n",
    "import os  # Usada para lidar com operações do sistema de arquivos\n",
    "import joblib # Biblioteca para salvar e carregar modelos e objetos Python\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA  # Importa o modelo ARIMA para análise de séries temporais\n",
    "from statsmodels.tsa.arima.model import ARIMA  # Importa o modelo ARIMA para análise de séries temporais\n",
    "from sklearn.linear_model import LinearRegression  # Importa o modelo de regressão linear\n",
    "from sklearn.model_selection import cross_val_score  # Importa função para validação cruzada\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit #\n",
    "from tabulate import tabulate  # Biblioteca para formatar tabelas\n",
    "from scipy import stats # Importa o módulo scipy.stats para estatísticas\n",
    "\n",
    "import warnings  # Biblioteca para controle de avisos durante a execução do código\n",
    "warnings.filterwarnings('ignore')  # Suprime avisos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dd7ed",
   "metadata": {},
   "source": [
    "#### 2 -  Obtendo todos os dados tratados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o Dataframe com a série histórica da coleta e tratamento de esgotos dos municipios de Goiás\n",
    "df = pd.read_csv('dados_GO/B - dado_tratado/df_municipios_habitantes_saneamento_codigo.csv', \n",
    "                delimiter = ';',\n",
    "                encoding = 'utf-8',\n",
    "                index_col= False)\n",
    "\n",
    "# Ordenando o DataFrame df por Município e Ano\n",
    "df = df.sort_values(['Município', 'Ano'])\n",
    "\n",
    "# Visualizando os primeiros 5 registros do Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame 'df_go' que agrupa a população urbana por ano\n",
    "df_go = pd.DataFrame(df.groupby('Ano')['Volume de esgoto produzido - 1000 m³', \n",
    "                                        'Volume de esgotos coletado - 1000 m³',\n",
    "                                        'Volume de esgotos tratado - 1000 m³'].sum()).reset_index()\n",
    "\n",
    "\n",
    "# Exibindo as primeiras linhas do DataFrame 'df_ano'\n",
    "df_go.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3a723",
   "metadata": {},
   "source": [
    "#### 3 -  Criando as variáveis e métodos que serão usados nos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e731a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando o DataFrame para anos maiores que 1996\n",
    "# Será usado nas previsões das features 'Volume de esgotos coletado - 1000 m³' e 'Volume de esgotos tratado - 1000 m³'\n",
    "df_filtered = df_go[df_go['Ano'] > 1996]\n",
    "\n",
    "# Definindo nomes das colunas relevantes\n",
    "nome_coluna_produzido = 'Volume de esgoto produzido - 1000 m³'\n",
    "nome_coluna_coletado = 'Volume de esgotos coletado - 1000 m³'\n",
    "nome_coluna_tratado = 'Volume de esgotos tratado - 1000 m³'\n",
    "nome_coluna_municipio = 'Município'\n",
    "nome_coluna_ano = 'Ano'\n",
    "\n",
    "# Separando as variáveis independentes e dependentes para análises futuras\n",
    "X1 = df_go[nome_coluna_ano]\n",
    "X2 = df_filtered[nome_coluna_ano] \n",
    "\n",
    "y1 = df_go[nome_coluna_produzido]\n",
    "y2 = df_filtered[nome_coluna_coletado]\n",
    "y3 = df_filtered[nome_coluna_tratado]\n",
    "\n",
    "# Definindo nomes das colunas para clusters \n",
    "nome_coluna_cluster_produzido = 'Cluster_produzido'\n",
    "nome_coluna_cluster_coletado = 'Cluster_coletado'\n",
    "nome_coluna_cluster_tratado = 'Cluster_tratado'\n",
    "\n",
    "# Pivotando o DataFrame para análises futuras\n",
    "# Será usado na clusterização\n",
    "df_pivot_produzido = df.pivot(index=nome_coluna_municipio, columns=nome_coluna_ano, values=nome_coluna_produzido)\n",
    "df_pivot_coletado = df.pivot(index=nome_coluna_municipio, columns=nome_coluna_ano, values=nome_coluna_coletado)\n",
    "df_pivot_tratado = df.pivot(index=nome_coluna_municipio, columns=nome_coluna_ano, values=nome_coluna_tratado)\n",
    "\n",
    "# Estabelecendo uma faixa de anos futuros\n",
    "anos_futuros = np.arange(2022, 2033).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_metodo_cotovelo(df, num_clusters_range = range(1, 11)):\n",
    "    # Copiando o DataFrame para evitar modificações no original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Normalizando os dados usando o StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df_normalizado = scaler.fit_transform(df)\n",
    "    \n",
    "    # Definindo uma semente (SEED) para tornar os resultados reprodutíveis\n",
    "    SEED = 121\n",
    "    \n",
    "    # Inicializando uma lista para armazenar os valores de inércia\n",
    "    valores_inercia = []\n",
    "    \n",
    "    # Iterando sobre o número de clusters especificado\n",
    "    for num_clusters in num_clusters_range:\n",
    "        # Criando um modelo K-Means com o número de clusters atual\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=SEED)\n",
    "        \n",
    "        # Atribuindo cada ponto de dados a um cluster e calculando a inércia\n",
    "        df['Cluster'] = kmeans.fit_predict(df_normalizado)\n",
    "        valores_inercia.append(kmeans.inertia_)   \n",
    "        \n",
    "    # Retornando os valores de inércia e a faixa de números de clusters\n",
    "    return valores_inercia, num_clusters_range\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aplicar_modelo_kmeans(df, num_clusters):\n",
    "    # Copiando o DataFrame para evitar modificações no original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Normalizando os dados usando o StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df_cluster_normalizado = scaler.fit_transform(df)\n",
    "    \n",
    "    # Definindo uma semente (SEED) para tornar os resultados reprodutíveis\n",
    "    SEED = 121\n",
    "    \n",
    "    # Criando um modelo K-Means com o número de clusters especificado\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=SEED)\n",
    "    \n",
    "    # Atribuindo cada ponto de dados a um cluster e armazenando em um dicionário\n",
    "    df['Cluster'] = kmeans.fit_predict(df_cluster_normalizado)\n",
    "    dicionario = df.to_dict()['Cluster']\n",
    "    \n",
    "    # Retornando o dicionário com atribuições de cluster\n",
    "    return dicionario\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def definir_cor_aleatoria():\n",
    "    # Gerando valores aleatórios para os canais de cor (vermelho, verde e azul).\n",
    "    red = random.randint(0, 200)\n",
    "    green = random.randint(0, 200)\n",
    "    blue = random.randint(0, 200)\n",
    "    \n",
    "    # Criando uma representação hexadecimal da cor combinando os canais de cor.\n",
    "    cor = \"#{:02x}{:02x}{:02x}\".format(red, green, blue)\n",
    "    \n",
    "    # Retornando a cor gerada no formato \"#RRGGBB\".\n",
    "    return cor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plotar_grafico_simples(x, y, titulo, rotulo_x, rotulo_y):\n",
    "    # Gerando uma cor aleatória para o gráfico\n",
    "    cor = definir_cor_aleatoria()\n",
    "    \n",
    "    # Criando uma figura para o gráfico com tamanho específico\n",
    "    plt.figure(figsize=(12, 8))  \n",
    "    \n",
    "    # Plotando os dados no gráfico usando marcadores, linha e a cor aleatória\n",
    "    plt.plot(x, y, marker='o', linestyle='-', color=cor)  \n",
    "    \n",
    "    # Adicionando um título ao gráfico\n",
    "    plt.title(titulo) \n",
    "    \n",
    "    # Adicionando rótulos aos eixos X e Y\n",
    "    plt.xlabel(rotulo_x) \n",
    "    plt.ylabel(rotulo_y)  \n",
    "    \n",
    "    # Ativando a grade no gráfico\n",
    "    plt.grid(True) \n",
    "    \n",
    "    # Exibindo o gráfico\n",
    "    plt.show()\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "def plotar_unico_grafico_multi_curvas(x_values, y_values, titulo, rotulo, eixos):\n",
    "    # Criando uma figura para o gráfico com tamanho específico\n",
    "    plt.figure(figsize=(12, 8)) \n",
    "    \n",
    "    # Iterando sobre as curvas para plotar cada uma com uma cor aleatória e rótulo\n",
    "    for i in range(len(x_values)):\n",
    "        cor = definir_cor_aleatoria()\n",
    "        plt.plot(x_values[i], y_values[i], color=cor, label=rotulo[i])\n",
    "    \n",
    "    # Adicionando um título ao gráfico\n",
    "    plt.title(titulo) \n",
    "    \n",
    "    # Adicionando rótulos aos eixos X e Y\n",
    "    plt.xlabel(eixos[0]) \n",
    "    plt.ylabel(eixos[1])  \n",
    "    \n",
    "    # Adicionando uma legenda para as curvas\n",
    "    plt.legend()\n",
    "    \n",
    "    # Ativando a grade no gráfico\n",
    "    plt.grid(True)  \n",
    "    \n",
    "    # Exibindo o gráfico\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def plotar_graficos_multiplos(df, coluna_grupo, x, y, linhas, separar_por):\n",
    "    # Obtendo os valores únicos que serão usados para separar os dados\n",
    "    separador = df[separar_por].unique()\n",
    "    \n",
    "    # Iterando sobre os valores de separação\n",
    "    for valor in separador:\n",
    "        # Filtrando o DataFrame com base no valor de separação\n",
    "        df_filtrado = df[df[separar_por] == valor]\n",
    "        \n",
    "        # Obtendo os valores únicos da coluna de agrupamento\n",
    "        coluna_grupo_unico = df_filtrado[coluna_grupo].unique()\n",
    "        \n",
    "        # Gerando uma cor aleatória para cada conjunto de dados\n",
    "        cor = definir_cor_aleatoria()\n",
    "        \n",
    "        # Imprimindo o valor atual de separação\n",
    "        print(separar_por +': '+ str(valor))\n",
    "        \n",
    "        # Calculando o número de linhas necessário para os subplots\n",
    "        num_linhas = int(np.ceil(len(coluna_grupo_unico) / linhas))\n",
    "        \n",
    "        # Iterando sobre as linhas de subplots\n",
    "        for linha in range(num_linhas):\n",
    "            # Selecionando o grupo de colunas para esta linha de subplots\n",
    "            coluna_grupo_linha = coluna_grupo_unico[linha * linhas:(linha + 1) * linhas]\n",
    "            \n",
    "            # Criando uma figura para os subplots\n",
    "            plt.figure(figsize=(20, 3))\n",
    "            \n",
    "            # Iterando sobre as colunas dentro da linha de subplots\n",
    "            for i, coluna_unico_grupo in enumerate(coluna_grupo_linha):\n",
    "                # Selecionando os dados para o grupo atual\n",
    "                df_unico_grupo = df_filtrado[df_filtrado[coluna_grupo] == coluna_unico_grupo]\n",
    "                \n",
    "                # Criando um subplot na posição atual\n",
    "                plt.subplot(1, linhas, i + 1)\n",
    "                \n",
    "                # Plotando os dados\n",
    "                plt.plot(df_unico_grupo[x], df_unico_grupo[y], color=cor)\n",
    "                \n",
    "                # Definindo os rótulos e títulos dos subplots\n",
    "                plt.xticks([]) \n",
    "                plt.yticks([]) \n",
    "                titulo_quebrado = '\\n'.join(coluna_unico_grupo.split())\n",
    "                plt.title(f'{titulo_quebrado}')\n",
    "                plt.xlabel(x)\n",
    "                plt.ylabel(y)\n",
    "            \n",
    "            # Ajustando o layout dos subplots para melhor exibição\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Exibindo os subplots\n",
    "            plt.show()\n",
    "            \n",
    "            # Fechando a figura atual\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "def validar_cruzadamente(cv, X, y):\n",
    "    # Criando uma instância de modelo de regressão linear\n",
    "    modelo = LinearRegression()\n",
    "    \n",
    "    # Realizando validação cruzada e obtendo pontuações de erro quadrático médio negativo\n",
    "    scores = cross_val_score(modelo, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Mantendo os valores negativos do erro quadrático médio (os valores são negativos por padrão)\n",
    "    mse_scores = -scores\n",
    "    \n",
    "    # Calculando a média dos valores do erro quadrático médio\n",
    "    mean_mse = mse_scores.mean()\n",
    "    \n",
    "    # Retornando a média do erro quadrático médio e o modelo treinado\n",
    "    return mean_mse, modelo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def medir_desempenho_grau_regressao_polinomial(X, y, cv=5, graus=list(range(1, 11))):\n",
    "    # Lista para armazenar as métricas de desempenho\n",
    "    desempenho = []\n",
    "    \n",
    "    # Iterando sobre os diferentes graus de polinômios\n",
    "    for grau in graus:\n",
    "        # Criando recursos polinomiais com o grau especificado\n",
    "        poly_features = PolynomialFeatures(degree=grau)\n",
    "        X_poly = poly_features.fit_transform(X) \n",
    "        \n",
    "        # Medindo o desempenho do modelo com validação cruzada\n",
    "        mean_mse, modelo = validar_cruzadamente(cv, X_poly, y)\n",
    "        \n",
    "        # Treinando o modelo\n",
    "        modelo.fit(X_poly, y)\n",
    "        \n",
    "        # Fazendo previsões\n",
    "        y_pred = modelo.predict(X_poly)\n",
    "        \n",
    "        # Calculando o coeficiente de determinação (R²)\n",
    "        r_squared = r2_score(y, y_pred)\n",
    "        \n",
    "        # Armazenando as métricas de desempenho em uma lista\n",
    "        desempenho.append(f'Grau:{grau}, \\\n",
    "        Raiz do Erro Quadrático Médio (RMSE):{np.sqrt(mean_mse).round(2)},\\\n",
    "        R²:{r_squared.round(6)}')\n",
    "    \n",
    "    return desempenho\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aplicar_regressao_polinomial(X, y, graus):\n",
    "    # Criando instância do objeto PolynomialFeatures com o grau especificado\n",
    "    feature_poli = PolynomialFeatures(degree=graus)\n",
    "    \n",
    "    # Transformando os recursos de entrada em recursos polinomiais\n",
    "    X_poly = feature_poli.fit_transform(X.values.reshape(-1, 1))\n",
    "    \n",
    "    # Criando um modelo de regressão linear\n",
    "    modelo = LinearRegression()\n",
    "    \n",
    "    # Treinando o modelo com os recursos polinomiais e os valores de saída\n",
    "    modelo.fit(X_poly, y)\n",
    "    \n",
    "    # Fazendo previsões usando o modelo treinado\n",
    "    y_pred = modelo.predict(X_poly)\n",
    "    \n",
    "    # Retornando as previsões, o modelo treinado e o objeto PolynomialFeatures\n",
    "    return y_pred, modelo, feature_poli\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aplicar_regressao_linear(X, y, cv=5):\n",
    "    # Calculando o erro médio quadrático médio e obtendo o modelo através de validação cruzada\n",
    "    mean_mse, modelo = validar_cruzadamente(cv, X.values.reshape(-1, 1), y)\n",
    "    \n",
    "    # Treinando o modelo linear com os dados de entrada e saída\n",
    "    modelo.fit(X.values.reshape(-1, 1), y)\n",
    "    \n",
    "    # Realizando previsões com o modelo treinado\n",
    "    y_pred = modelo.predict(X.values.reshape(-1, 1))\n",
    "    \n",
    "    # Calculando o coeficiente de determinação R² para avaliar o modelo\n",
    "    r_squared = r2_score(y, y_pred)\n",
    "  \n",
    "    # Retornando as previsões, o modelo, o erro médio quadrático médio e o R²\n",
    "    return y_pred, modelo, mean_mse, r_squared\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def medir_desempenho_ARIMA(X, y, p_values=range(0, 2), d_values=range(0, 2), q_values=range(0, 2)):\n",
    "    # Criando uma série temporal a partir dos dados de entrada\n",
    "    serie_temporal = pd.Series(y)\n",
    "    serie_temporal.index = X\n",
    "    \n",
    "    # Lista para armazenar as métricas de desempenho para diferentes combinações de p, d e q\n",
    "    desempenho = []\n",
    "    \n",
    "    # Iterando através de todas as combinações de p, d e q\n",
    "    for p, d, q in itertools.product(p_values, d_values, q_values):\n",
    "        # Configurando a validação cruzada em séries temporais com 5 splits\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        mse_scores = []  # Lista para armazenar os valores do erro quadrático médio\n",
    "        r_squared_scores = []  # Lista para armazenar os valores do coeficiente de determinação (R²)\n",
    "        \n",
    "        # Iterando através dos splits da validação cruzada\n",
    "        for train_idx, test_idx in tscv.split(serie_temporal):\n",
    "            train_fold, test_fold = serie_temporal.iloc[train_idx], serie_temporal.iloc[test_idx]\n",
    "            \n",
    "            # Treinando o modelo ARIMA\n",
    "            model_arima = ARIMA(train_fold, order=(p, d, q))\n",
    "            model_arima_fit = model_arima.fit()\n",
    "            \n",
    "            # Realizando previsões com base no modelo treinado\n",
    "            predictions = model_arima_fit.forecast(steps=len(test_fold))\n",
    "            \n",
    "            # Calculando o erro quadrático médio\n",
    "            mse = mean_squared_error(test_fold, predictions)\n",
    "            mse_scores.append(mse)\n",
    "            \n",
    "            # Calculando o coeficiente de determinação (R²)\n",
    "            r_squared = r2_score(test_fold, predictions)\n",
    "            r_squared_scores.append(r_squared)\n",
    "        \n",
    "        # Calculando as métricas médias para esta combinação de p, d e q\n",
    "        avg_mse = np.mean(mse_scores)\n",
    "        avg_r_squared = np.mean(r_squared_scores)\n",
    "        \n",
    "        # Armazenando as métricas de desempenho na lista\n",
    "        desempenho.append(f'(p={p}; d={d}; q={q}), \\\n",
    "AIC: {model_arima_fit.aic.round(2)}, \\\n",
    "Raiz do Erro Quadrático Médio: {np.sqrt(avg_mse).round(2)}, \\\n",
    "Coeficiente de Determinação (R²): {avg_r_squared.round(6)}')\n",
    "    \n",
    "    # Retornando as métricas de desempenho para diferentes combinações de p, d e q\n",
    "    return desempenho\n",
    "\n",
    "\n",
    "# Criando um DataFrame para análise estatística\n",
    "def calcular_p_value_alpha_05(x, y_real, y_pred):\n",
    "    df_teste_p_valor = pd.DataFrame({'Ano': x, 'Valor Real': y_real, 'Valor Previsto': y_pred})\n",
    "    \n",
    "    # Calculando a diferença entre os valores previstos e reais\n",
    "    df_teste_p_valor['Diferença'] = df_teste_p_valor['Valor Previsto'] - df_teste_p_valor['Valor Real']\n",
    "    \n",
    "    # Realizando o teste t de amostras pareadas\n",
    "    t_statistic, p_valor = stats.ttest_rel(df_teste_p_valor['Valor Previsto'], \n",
    "                                       df_teste_p_valor['Valor Real'])\n",
    "    \n",
    "    # Definindo o nível de significância (alpha)\n",
    "    alpha = 0.05  \n",
    "    \n",
    "    # Verificando se a diferença é estatisticamente significativa\n",
    "    if p_valor < alpha:\n",
    "        print(f\"Diferença estatisticamente significativa (p_value:{p_valor.round(8)})\")\n",
    "    else:\n",
    "        print(f\"Não há diferença estatisticamente significativa (p_value:{p_valor.round(8)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9da828",
   "metadata": {},
   "source": [
    "#### 3 -  Clusterizando os municípios de Goiás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o Método Elbow Curve (método do cotovelo) em cada feature para encontrar a quantidade ideal de clusters K\n",
    "inercia_produzido, cluster_produzido = aplicar_metodo_cotovelo(df_pivot_produzido)\n",
    "inercia_coletado, cluster_coletado = aplicar_metodo_cotovelo(df_pivot_coletado)\n",
    "inercia_tratado, cluster_tratado = aplicar_metodo_cotovelo(df_pivot_tratado)\n",
    "\n",
    "# Plotando o gráfico com os dados obtidos por intermédio do Método Elbow Curve (método do cotovelo) \n",
    "print('Método do Cotovelo para Determinar o Número de Cluster(s)')\n",
    "plotar_grafico_simples(cluster_produzido, inercia_produzido, nome_coluna_produzido, 'Nº de cluster(s)', 'Inércia')\n",
    "plotar_grafico_simples(cluster_coletado, inercia_coletado, nome_coluna_coletado, 'Nº de cluster(s)', 'Inércia')\n",
    "plotar_grafico_simples(cluster_tratado, inercia_tratado, nome_coluna_tratado, 'Nº de cluster(s)', 'Inércia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo o número de cluster que será aplicado ao modelo\n",
    "# Este valor foi obtido por intermédio do por intermédio do Método Elbow Curve (método do cotovelo) \n",
    "clusters = 3\n",
    "\n",
    "\n",
    "# Criando uma cópia do DataFrame df para que seja utilizado unicamente neste modelo\n",
    "df_cluster = df.copy()\n",
    "\n",
    "# Gerando a clusterização a partir do Modelo k-means\n",
    "# Após a aplicação do modelo, será retornado diciniário com o valor do cluster de cada município\n",
    "modelo_produzido = aplicar_modelo_kmeans(df_pivot_produzido, clusters)\n",
    "modelo_coletado = aplicar_modelo_kmeans(df_pivot_coletado, clusters)\n",
    "modelo_tratado = aplicar_modelo_kmeans(df_pivot_tratado, clusters)\n",
    "\n",
    "# Gerando 3 novas colunas para armezenar o cluster de cada feature\n",
    "df_cluster['Cluster_produzido'] = df_cluster['Município'].map(modelo_produzido)\n",
    "df_cluster['Cluster_coletado'] = df_cluster['Município'].map(modelo_coletado)\n",
    "df_cluster['Cluster_tratado'] = df_cluster['Município'].map(modelo_tratado)\n",
    "\n",
    "# Estabelecendo a quantidade de gráficos que cada linha terá quando os dados forem plotados\n",
    "linhas = 14\n",
    "\n",
    "# Plotando o gráfico com os dados obtidos após a clusterização dos Municipíos\n",
    "print('Clusterização: Volume de esgoto produzido - 1000 m³')\n",
    "#Gráfico 1 - Clusterização dos municípios conforme a feature \"Volume de esgoto produzido - 1000 m³\"\n",
    "plotar_graficos_multiplos(df_cluster, nome_coluna_municipio, nome_coluna_ano, \n",
    "                        nome_coluna_produzido, linhas, nome_coluna_cluster_produzido)\n",
    "\n",
    "print('Clusterização: Volume de esgotos coletado - 1000 m³')\n",
    "#Gráfico 2 - Clusterização dos municípios conforme a feature \"Volume de esgotos coletado - 1000 m³\"\n",
    "plotar_graficos_multiplos(df_cluster, nome_coluna_municipio, nome_coluna_ano, \n",
    "                        nome_coluna_coletado, linhas, nome_coluna_cluster_coletado)\n",
    "\n",
    "print('Clusterização: Volume de esgotos tratado - 1000 m³')\n",
    "#Gráfico 3 - Clusterização dos municípios conforme a feature \"Volume de esgotos tratado - 1000 m³'\"\n",
    "plotar_graficos_multiplos(df_cluster, nome_coluna_municipio, nome_coluna_ano, \n",
    "                        nome_coluna_tratado, linhas, nome_coluna_cluster_tratado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se a pasta \"dados_GO/D - dado_predito/kmeans\" já existe\n",
    "if not os.path.exists('dados_GO/D - dado_predito/kmeans'):\n",
    "    # Se não existir, cria a pasta\n",
    "    os.makedirs('dados_GO/D - dado_predito/kmeans')\n",
    "\n",
    "#Salvando o arquivo CSV no diretório \"dados_GO/D - dado_predito/kmeans\" como dados relativos à clusterização \n",
    "df_cluster.to_csv('dados_GO/D - dado_predito/kmeans/\\\n",
    "           df_predito_kmeans.csv', \n",
    "           index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcbfe8",
   "metadata": {},
   "source": [
    "#### 4 -  Aplicando Regressão Poliminal aos dados agrupados para o estado de Goiás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estabelecendo o número de dobras que será empregado na validação cruzada\n",
    "cv = 5\n",
    "\n",
    "# Aplicando o modelo de regressão poliminal em cada feature\n",
    "desempenho_produzido = medir_desempenho_grau_regressao_polinomial(X1.values.reshape(-1, 1), y1, cv)\n",
    "desempenho_coletado = medir_desempenho_grau_regressao_polinomial(X2.values.reshape(-1, 1), y2, cv)\n",
    "desempenho_tratado = medir_desempenho_grau_regressao_polinomial(X2.values.reshape(-1, 1), y3, cv)\n",
    "\n",
    "print('** Regressão Polinomial: Volume de esgoto produzido - 1000 m³ ** ')\n",
    "tabela = [item.split(', ') for item in desempenho_produzido]\n",
    "print(tabulate(tabela, tablefmt='fancy_grid'))\n",
    "print('\\n')\n",
    "\n",
    "print('** Regressão Polinomial: Volume de esgotos coletado - 1000 m³ **')\n",
    "tabela = [item.split(', ') for item in desempenho_coletado]\n",
    "print(tabulate(tabela, tablefmt='fancy_grid'))\n",
    "print('\\n')\n",
    "\n",
    "print('** Regressão Polinomial: Volume de esgotos tratado - 1000 m³ **')\n",
    "tabela = [item.split(', ') for item in desempenho_tratado]\n",
    "print(tabulate(tabela, tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7dece",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Atribuindo o valor do grau de cada modelo\n",
    "# Este valor foi obtido por intermédio do por intermédio da função de avaliação de empenho\n",
    "grau_produzido = 10\n",
    "grau_coletado = 3\n",
    "grau_tratado = 3\n",
    "\n",
    "# Aplicando o modelo de regrassão polinomial aos dados\n",
    "# Após a aplicação do modelo, serão retornados os valores preditos de teste\n",
    "pred_y_poli_produzido, modelo_poli_produzido, feature_poli_produzido = aplicar_regressao_polinomial(X1, y1, 10)\n",
    "pred_y_poli_coletado, modelo_poli_coletado, feature_poli_coletado = aplicar_regressao_polinomial(X2, y2, 3)\n",
    "pred_y_poli_tratado, modelo_poli_tratado, feature_poli_tratado = aplicar_regressao_polinomial(X2, y3, 3)\n",
    "\n",
    "# Criando duas cópias do DataFrame df para que sejam utilizados unicamente neste modelo\n",
    "df_reg_poli_teste_prod = df_go.copy().drop(columns=[\"Volume de esgotos coletado - 1000 m³\",\"Volume de esgotos tratado - 1000 m³\"])\n",
    "df_reg_poli_teste_prod['Volume de esgoto produzido - 1000 m³ (previsto em teste) '] = pred_y_poli_produzido\n",
    "df_reg_poli_teste_col_trat = df_filtered.copy().drop(columns=[\"Volume de esgoto produzido - 1000 m³\"])\n",
    "df_reg_poli_teste_col_trat['Volume de esgoto coletado - 1000 m³ (previsto em teste)'] = pred_y_poli_coletado\n",
    "df_reg_poli_teste_col_trat['Volume de esgoto tratado - 1000 m³ (previsto em teste)'] = pred_y_poli_tratado\n",
    "\n",
    "# Plotando o gráfico com os dados reais e os dados preditos no teste e definindo o p_value\n",
    "titulo_produzido = 'Série Histórica - '+ nome_coluna_produzido\n",
    "titulo_coletado = 'Série Histórica - '+ nome_coluna_coletado\n",
    "titulo_tratado = 'Série Histórica - '+ nome_coluna_tratado\n",
    "label_real = 'Valores reais'\n",
    "label_prev = 'Valores previstos'\n",
    "\n",
    "plotar_unico_grafico_multi_curvas([X1, X1], [y1, pred_y_poli_produzido], \n",
    "                                  titulo_produzido, [label_real, label_prev], [nome_coluna_ano,nome_coluna_produzido])\n",
    "calcular_p_value_alpha_05(X1.values, y1.values, pred_y_poli_produzido)\n",
    "plotar_unico_grafico_multi_curvas([X2, X2], [y2, pred_y_poli_coletado], \n",
    "                                  titulo_coletado, [label_real, label_prev], [nome_coluna_ano,nome_coluna_coletado])\n",
    "calcular_p_value_alpha_05(X2.values, y2.values, pred_y_poli_coletado)\n",
    "plotar_unico_grafico_multi_curvas([X2, X2], [y3, pred_y_poli_tratado], \n",
    "                                  titulo_tratado, [label_real, label_prev], [nome_coluna_ano,nome_coluna_tratado])\n",
    "calcular_p_value_alpha_05(X2.values, y3.values, pred_y_poli_tratado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se a pasta \"dados_GO/D - dado_predito/regressao_polinomial/teste\" já existe\n",
    "if not os.path.exists('dados_GO/D - dado_predito/regressao_polinomial/teste'):\n",
    "    # Se não existir, cria a pasta\n",
    "    os.makedirs('dados_GO/D - dado_predito/regressao_polinomial/teste')\n",
    "\n",
    "# Verificando se a pasta \"dados_GO/D - dado_predito/regressao_polinomial/modelo\" já existe\n",
    "if not os.path.exists('dados_GO/D - dado_predito/regressao_polinomial/modelos'):\n",
    "    # Se não existir, cria a pasta\n",
    "    os.makedirs('dados_GO/D - dado_predito/regressao_polinomial/modelos')\n",
    "\n",
    "#Salvando o arquivo CSV e o Modelo de Regressão no diretório \"dados_GO/D - dado_predito/regressao_polinomial/teste/\" \n",
    "#como dados relativos à clusterização \n",
    "df_reg_poli_teste_prod.to_csv('dados_GO/D - dado_predito/regressao_polinomial/teste/df_reg_poli_teste_prod.csv', \n",
    "                              index=False, sep=';')\n",
    "df_reg_poli_teste_col_trat.to_csv('dados_GO/D - dado_predito/regressao_polinomial/teste/df_reg_poli_teste_col_trat.csv', \n",
    "                                  index=False, sep=';')\n",
    "\n",
    "joblib.dump(modelo_poli_produzido, 'dados_GO/D - dado_predito/regressao_polinomial/modelos/modelo_reg_poli_produzido.pkl')\n",
    "joblib.dump(modelo_poli_coletado, 'dados_GO/D - dado_predito/regressao_polinomial/modelos/modelo_reg_poli_coletado.pkl')\n",
    "joblib.dump(modelo_poli_tratado, 'dados_GO/D - dado_predito/regressao_polinomial/modelos/modelo_reg_poli_tratado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5719e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o modelo de regressão polinomial aos dados para predição dos anos 2022 a 2032\n",
    "# Após a aplicação do modelo, serão retornados os valores preditos\n",
    "y_pred_poli_futuro_produzido = modelo_poli_produzido.predict(feature_poli_produzido.transform(anos_futuros))\n",
    "y_pred_poli_futuro_coletado = modelo_poli_coletado.predict(feature_poli_tratado.transform(anos_futuros))\n",
    "y_pred_poli_futuro_tratado = modelo_poli_tratado.predict(feature_poli_coletado.transform(anos_futuros))\n",
    "\n",
    "# Plotando o gráfico com os dados reais e os dados preditos\n",
    "X_multi = [X1, X2, X2, anos_futuros, anos_futuros, anos_futuros]\n",
    "y_multi = [y1, y2, y3, y_pred_poli_futuro_produzido, y_pred_poli_futuro_coletado, y_pred_poli_futuro_tratado]\n",
    "titulo = 'Série Histórica - Regressão Polinomial'\n",
    "label_real = ['Esgoto Produzido','Esgoto Coletado','Esgoto Tratado']\n",
    "label_prev = ['Esgoto Produzido Previsto','Esgoto Coletado Previsto','Esgoto Tratado Previsto']\n",
    "label_prev = label_real + label_prev\n",
    "label_x = ['Ano']\n",
    "label_y = ['Volume (1000³)']\n",
    "label_eixos = label_x + label_y\n",
    "\n",
    "plotar_unico_grafico_multi_curvas(X_multi, y_multi, titulo, label_prev, label_eixos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8f635",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Estabelecendo o número de dobras que será empregado na validação cruzada\n",
    "cv = 5\n",
    "\n",
    "# Aplicando o modelo de regressão lienar em cada feature\n",
    "pred_y_linear_produzido, modelo_linear_produzido, eqm_linear_produzido, r2_lienar_produzido =\\\n",
    "aplicar_regressao_linear(X1, y1, cv)\n",
    "pred_y_linear_coletado, modelo_linear_coletado, eqm_linear_coletado, r2_lienar_coletado =\\\n",
    "aplicar_regressao_linear(X2, y2, cv)\n",
    "pred_y_linear_tratado, modelo_linear_tratado, eqm_linear_tratado, r2_lienar_tratado =\\\n",
    "aplicar_regressao_linear(X2, y3, cv)\n",
    "\n",
    "\n",
    "# Plotando o gráfico com os dados reais e os dados preditos no teste e definindo o p_value\n",
    "titulo_produzido = 'Série Histórica - '+ nome_coluna_produzido\n",
    "titulo_coletado = 'Série Histórica - '+ nome_coluna_coletado\n",
    "titulo_tratado = 'Série Histórica - '+ nome_coluna_tratado\n",
    "label_real = 'Valores reais'\n",
    "label_prev = 'Valores previstos'\n",
    "\n",
    "plotar_unico_grafico_multi_curvas([X1, X1], [y1, pred_y_linear_produzido], \n",
    "                                  titulo_produzido, [label_real, label_prev], [nome_coluna_ano,nome_coluna_produzido])\n",
    "calcular_p_value_alpha_05(X1.values, y1.values, pred_y_linear_produzido)\n",
    "print(f'Raiz do Erro Quadrático Médio Médio (Cross-Validation): {np.sqrt(eqm_linear_produzido)}')\n",
    "print(f'Coeficiente de Determinação (R²): {r2_lienar_produzido.round(4)} \\n')\n",
    "plotar_unico_grafico_multi_curvas([X2, X2], [y2, pred_y_linear_coletado], \n",
    "                                  titulo_coletado, [label_real, label_prev], [nome_coluna_ano,nome_coluna_coletado])\n",
    "calcular_p_value_alpha_05(X2.values, y2.values, pred_y_linear_coletado)\n",
    "print(f'Raiz do Erro Quadrático Médio Médio (Cross-Validation): {np.sqrt(eqm_linear_coletado)}')\n",
    "print(f'Coeficiente de Determinação (R²): {r2_lienar_coletado.round(4)} \\n')\n",
    "plotar_unico_grafico_multi_curvas([X2, X2], [y3, pred_y_linear_tratado], \n",
    "                                  titulo_tratado, [label_real, label_prev], [nome_coluna_ano,nome_coluna_tratado])\n",
    "calcular_p_value_alpha_05(X2.values, y3.values, pred_y_linear_tratado)\n",
    "print(f'Raiz do Erro Quadrático Médio Médio (Cross-Validation): {np.sqrt(eqm_linear_tratado)}')\n",
    "print(f'Coeficiente de Determinação (R²): {r2_lienar_tratado.round(4)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o modelo de regressão linear aos dados para predição dos anos 2022 a 2032\n",
    "# Após a aplicação do modelo, serão retornados os valores preditos\n",
    "y_pred_futuro_lienar_produzido = modelo_linear_produzido.predict(anos_futuros)\n",
    "y_pred_futuro_linear_coletado = modelo_linear_coletado.predict(anos_futuros)\n",
    "y_pred_futuro_linear_tratado = modelo_linear_tratado.predict(anos_futuros)\n",
    "\n",
    "\n",
    "# Plotando o gráfico com os dados reais e os dados preditos\n",
    "X_multi = [X1, X2, X2, anos_futuros, anos_futuros, anos_futuros]\n",
    "y_multi = [y1, y2, y3, y_pred_futuro_lienar_produzido, y_pred_futuro_linear_coletado, y_pred_futuro_linear_tratado]\n",
    "titulo = 'Série Histórica - Regressão Linear'\n",
    "label_real = ['Esgoto Produzido','Esgoto Coletado','Esgoto Tratado']\n",
    "label_prev = ['Esgoto Produzido Previsto','Esgoto Coletado Previsto','Esgoto Tratado Previsto']\n",
    "label_prev = label_real + label_prev\n",
    "label_x = ['Ano']\n",
    "label_y = ['Volume (1000³)']\n",
    "label_eixos = label_x + label_y\n",
    "\n",
    "plotar_unico_grafico_multi_curvas(X_multi, y_multi, titulo, label_prev, label_eixos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe451981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_verificacao_coletado_tratado = {'Ano': anos_futuros.flatten(), \n",
    "        'Volume de Esgoto Coletado': y_pred_futuro_linear_coletado, \n",
    "        'Volume de Esgoto Tratado': y_pred_futuro_linear_tratado,\n",
    "        'Volume de Esgoto Produzido': y_pred_futuro_lienar_produzido}\n",
    "\n",
    "df_verificacao_coletado_tratado = pd.DataFrame(dic_verificacao_coletado_tratado)\n",
    "\n",
    "print('*** Ano em que todo o esgoto coletado estará sendo tratado: ***')\n",
    "df_verificacao_coletado_tratado[df_verificacao_coletado_tratado['Volume de Esgoto Tratado'] \n",
    "                                >= df_verificacao_coletado_tratado['Volume de Esgoto Coletado']].head(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Eficência do Volume de Esgoto tratado em 2032: ***')\n",
    "a = df_verificacao_coletado_tratado['Volume de Esgoto Tratado'][df_verificacao_coletado_tratado['Ano'] == 2032].values\n",
    "b = df_verificacao_coletado_tratado['Volume de Esgoto Produzido'][df_verificacao_coletado_tratado['Ano'] == 2032].values\n",
    "\n",
    "print(str(float(((a/b)*100).round(2)))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o modelo de regrassão linear aos dados para predição dos anos 2022 a 2032\n",
    "# Após a aplicação do modelo, serão retornados os valores preditos\n",
    "desempenho_arima_produzido = medir_desempenho_ARIMA(X1,y1, range(0, 2), range(0, 2), range(0, 4))\n",
    "desempenho_arima_coletado = medir_desempenho_ARIMA(X2,y2)\n",
    "desempenho_arima_tratado = medir_desempenho_ARIMA(X2,y3)\n",
    "\n",
    "print('** Modelo ARIMA: Volume de esgoto produzido - 1000 m³ ** ')\n",
    "tabela = [item.split(', ') for item in desempenho_arima_produzido]\n",
    "print(tabulate(tabela, tablefmt='fancy_grid'))\n",
    "print('\\n')\n",
    "\n",
    "print('** Modelo ARIMA: Volume de esgotos coletado - 1000 m³ **')\n",
    "tabela = [item.split(', ') for item in desempenho_arima_coletado]\n",
    "print(tabulate(tabela, tablefmt='fancy_grid'))\n",
    "print('\\n')\n",
    "\n",
    "print('** Modelo ARIMA: Volume de esgotos tratado - 1000 m³ **')\n",
    "tabela = [item.split(', ') for item in desempenho_arima_tratado]\n",
    "print(tabulate(tabela, tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b49dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se a pasta \"dados_GO/D - dado_predito/regressao_polinomial/teste\" já existe\n",
    "if not os.path.exists('dados_GO/D - dado_predito/ARIMA/modelo'):\n",
    "    # Se não existir, cria a pasta\n",
    "    os.makedirs('dados_GO/D - dado_predito/ARIMA/modelo')\n",
    "\n",
    "\n",
    "joblib.dump(desempenho_arima_produzido, 'dados_GO/D - dado_predito/ARIMA/modelo/modelo_arima_produzido.pkl')\n",
    "joblib.dump(modelo_poli_coletado, 'dados_GO/D - dado_predito/ARIMA/modelo/modelo_arima_coletado.pkl')\n",
    "joblib.dump(desempenho_arima_tratado, 'dados_GO/D - dado_predito/ARIMA/modelo/modelo_arima_tratado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2b41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
